% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Boost.R
\name{Boost}
\alias{Boost}
\title{Boost}
\usage{
Boost(x_train, y_train, x_val, y_val, x_test, y_test, type = "L2Boost",
  error = c("rmse", "aad"), niter = 200, y_init = "median",
  max_depth = 1, tree_init_provided = NULL,
  control = Boost.control())
}
\arguments{
\item{x_train}{predictor matrix for training data (matrix/dataframe)}

\item{y_train}{response vector for training data (vector/dataframe)}

\item{x_val}{predictor matrix for validation data (matrix/dataframe)}

\item{y_val}{response vector for validation data (vector/dataframe)}

\item{x_test}{predictor matrix for test data (matrix/dataframe, optional, required when make_prediction in control = TRUE)}

\item{y_test}{response vector for test data (vector/dataframe,  optional, required when make_prediction in control = TRUE)}

\item{type}{type of the boosting method: "L2Boost", "MBoost", "Robloss", "SBoost", "RRBoost". (string)}

\item{error}{types of the error metric on the test set: "rmse","aad"(average absulute deviation), or "trmse" (trimmed rmse) (array)}

\item{niter}{number of iterations (for RRBoost T_{1,max} + T_{2,max}) (numeric)}

\item{y_init}{the initial estimator, "median" or "LADTree" (string)}

\item{max_depth}{the maximum depth of the tree learners (numeric)}

\item{tree_init_provided}{provided fitted initial tree (rpart object)}

\item{control}{control parameters specified with Boost.control()}
}
\value{
A list with the following components:

\item{type}{type of the boosting estimator (e.g. 'RRBoost',"L2Boost")}
\item{control}{the input control parameters}
\item{niter}{number of iterations (for RRBoost T_{1,max} + T_{2,max}) (numeric)}
\item{error}{a vector of error values evaluated on the test set at early stopping time. The length of the vector depends on the `error` argument in the input.  (returned if make_prediction = TRUE in control).}
\item{tree_init}{the initial tree (rpart object, returned if y_init = "LADTree")}
\item{tree_list}{a list of trees fitted at each iteration (returned if save_tree = TRUE in control) }
\item{f_train_init}{a vector of initialized estimator of the training data}
\item{alpha}{a vector of base learners' coefficients}
\item{early_stop_idx}{early stopping iteration}
\item{when_init}{the early stopping time of the first stage of RRBoost (returned if type = "RRBoost)}
\item{loss_train}{a vector of training loss values}
\item{loss_val}{a vector of validation loss values}
\item{err_val}{a vector of validation aad error}
\item{err_train}{a vector of training aad error}
\item{err_test}{a matrix of test errors (returned if make_prediction = TRUE in control)}
\item{f_train}{matrix of training function estimates at all iterations (returned if save_f = TRUE in control)}
\item{f_val}{matrix of validation function estimates at all iterations (returned if save_f = TRUE in control)}
\item{f_test}{matrix of test function estimates at all iterations (returned if save_f = TRUE and make_prediction = TRUE in control)}
\item{var_importance}{vector of permutation importance at early stopping time (returned if cal_imp = TRUE in control)}
}
\description{
A function to fit RRBoost which includes options to fit L2Boost, LADBoost, MBoost, Robloss, and SBoost
}
\details{
A function to fit RRBoost which includes options to fit L2Boost, LADBoost, MBoost, Robloss, and SBoost
}
\author{
Xiaomeng Ju, \email{xmengju@stat.ubc.ca}
}
